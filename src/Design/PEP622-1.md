# Revision and Suggestions for PEP 622(V1)


## My Concerns

Python pattern matching is what in the very beginning motivates me, to study in the field of Programming Languages.

Now I'm skilled in more than 30 programming languages, and have developed a lot of interests in many other topics. My research topic is CPython compatible JIT compiler, it seems I cannot graduate if I cannot work it out.

From these facts, you know how special Python is to me.

Today, a friend of mine, [laike9m](https://laike9m.com/) referred me a tweet which talks about PEP 622, Structural Pattern Matching for Python..

My youth recalled!

Next, I read up the proposal, went to the cpython repo branch and checked the grammar.

There're quite a few issues with the PEP and maybe the implementations,
and I'd give my concerns in this article.

To convince the readers, I'd show my concerns with pattern matching stuffs:

1. I'm familiar with pattern matching in many programming languages(including the languages mentioned in PEP 622).

2. I understand the most complex and compelling parts of pattern matching in F#/OCaml, Haskell.

3. I wrote lots of Scala code during some period, and I nearly only use case classes + abstract classes(using ADTs), and traits.

4. I studied Elixir and Erlang and used to earn money with them, by writing games. Especially, I love Elixir's pin-operators.

5. I wrote lots of pattern matching implementations for Python:
    - [moshmosh](https://github.com/thautwarm/moshmosh)(it's a Japanese phrase used in phone calls), which provides a nearly full-featured pattern matching implementation(most stuffs mentioned in PEP 622 are implemented there), and I'm pretty sure this is so far the fastest implementation because I do code generation statically.
    - [Xython/pattern-matching](https://github.com/Xython/pattern-matching), this is only for fun. The infrastructure of this library is conceptually the same as the very popular one PamPy, but I did this in year 2017.

6. I also implemented the [Extensible Pattern Matching for Julia Programming Language](https://github.com/thautwarm/MLStyle.jl). Unlike moshmosh and Xython/pattern-matching, this library is actually widely in use because it's very efficient, extensible and effective.

7. (this item is a little bit academic)I have understandings about pattern matching from some other point of views, for instance, I can use denotational semantics to show the underlying structures of pattern matching: [First-class Pattern Matching in the Final Approach](https://thautwarm.github.io/Site-32/PL/tagless-final-pattern-match.html).

8. Maybe people in Python-ideas mailing list could remember what I post there in the summer of 2017. I modified CPython codebase and made something called "flowpython", it supports basic pattern matching but is quite naive/limited. Besides, I learned *BNF from CPython project, thanks a lot, now I'm quite skilled in parsing things.. that's another story..

## `__match__` protocol is inconvenient and inefficient.


Let me firstly introduce an alternative `__match__` protocol.

- RULE: no args

  `match v: case C()` matches, if
   
  `bool(C.__match__(v, 0, ())) is ()`.

- RULE: only positional args
   
  `match v: case C(a1, a2, ..., an)` matches, if

  `C.__match__(v, n, ())` matches a sequence pattern `(a1, ..., an)`.

- RULE: only keyword args
  
  `match v: case C(k1=kp1, ..., kn=kpn)` matches, if

  `C.__match__(v, 0, ('k1', ..., 'kn'))` matches a tuple pattern `(kp1, ..., kpn)`.

- RULE: positional + keyword

  `match v: case C(a1, ..., am, k1=kp1, ..., kn=kpn)` matches, if

  `C.__match__(v, m, ('k1', ..., 'kn'))` matches a tuple pattern `(a1, ..., am, kp1, ..., kpn)`

In fact, above 4 rules are consistent, and can be unified into one.

I separated them into 4, to show this is **FULL-FEATURED**, which means it can cover the functionalities of the `__match__` protocol presented in PEP 622.


**The advantage of this alternative design** will make the custom patterns
- **simpler to write and understand**, and
- **more efficient in runtime**, and
- **more expressive**

### Simplicity of the alternative `__match__` protocol

Avoiding `__match_args__` already brings simplicity.

Besides, as the PEP says, `InRange` shall be made with custom patterns,
we could consider its implementation.

After reading the PEP, I got to know how to implement this:

```python
class Check:
    def __init__(self, f):
        self.f = f
    def __eq__(self, o):
        return self.f(o)

class InRangeProxy:
    def __init__(self, lo_check, hi_check):
        self.lo_check, self.hi_check = lo_check, hi_check
    
class InRange:
    __match_args__ = ['lo_check', 'hi_check']

    def __init__(self, lo, hi):
        self.lo, self.hi = lo, hi
    
    def __match__(self, instance):
        return InRangeProxy(
            Check(lambda lo: lo <= instance),
            Check(lambda hi: instance < hi)
        )

match 5:
    case InRange(0, 10):
        ...
```

However, with the protocol proposed in this article:

```python
class Check:
    def __init__(self, f):
        self.f = f
    def __eq__(self, o):
        return self.f(o)

class InRange:
    def __match__(self, instance):
        return (
            Check(lambda lo: lo <= instance),
            Check(lambda hi: instance < hi)
        )

match 5:
    case InRange(0, 10):
        ...
```

Works exactly the same.

We will get the following benefits:

- we avoid introducing a `__match_args__` 
- we avoid introducing a proxy type
- the return of `__match__` has a shape quite similar to the pattern.

### Efficiency of the alternative `__match__` protocol

Using a proxy type can result in more allocations, but this is not the most severe drawbacks.

The most crucial 2 drawbacks of current `__match__` protocol are:

1. it cannot verify the validation of argument count/keyword names earlier.
2. `__match_args__` produces an indirect lookup.

**For the first point**:

```python
match expr:
    case C1(a=C2(...), b=C3(...), c=C4(...)):
        ...
```

Now, tell me, what if destructuring `C1` should only accept keyword arguments `a` and `b`?

Currently, should we have to compute the matching for `C2(...)`, `C3(...)`, then find `c=C4(...)` invalid.

This is inefficient.

Also, when it comes to the positional arguments, currently we can limitedly check if the argument count is valid, by checking the count of sub-patterns with `len(__match_args__)`. However our proposal `__match__` protocol allows more flexible checks. See [Better Expressiveness](#Better-expressiveness) for more details.

Anyway, with our proposal `__match__` protocol, we can fail a match in proper time, to avoid redundant computations.

**For the second point**, indirect lookups can be expensive for tiny operations:

```ipython
In [1]: x = [1, 2, 3]

In [2]: y = ["aaa", "bbb", "aba"]


In [3]: class S:
   ...:     def __init__(self, kws, args):
   ...:          for kw, arg in zip(kws, args):
   ...:              setattr(self, kw, arg)
   ...:          self._kws = kws
 
In [4]: s = S(y, x)

In [5]: %timeit x[1]
73.1 ns ± 1.54 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)

In [6]: %timeit getattr(s, s._kws[1])
296 ns ± 8.25 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)
```

With compiler tricks, we can make `getattr(s, s._kws[1])` faster, but it shall be still far slower than `x[1]`.

### Better Expressiveness

So far, the design for patterns `[]` is **generic**, which means `Sequence` instead of `list`, which can be non-intuitive in some degree.

Why not support `Sequence(a1, a2, *aseq, an)`?

This is sufficient to support `Sequence` interface, and can be implemented with our proposal `__match__` protocol. *Besides, with our design, `*` in class patterns is naturally supported.*

It's considered useful to support arbitrary number of positional arguments for our custom patterns:

- We have many kinds of data structure interfaces, other than only `Sequence` and `Mapping`.
- We can then leave list literals(`[*_]`) as-is, I mean this should only matches a list instead of any `Sequence`s.

## Comments about the rejection of AND (&) patterns

> However, it's not clear how useful this would be...

This can be extremely useful when working with custom patterns.

```python
match value:
    case P1(a, b) and P2(c) when pred(a, b, c):
        ...
```

`P1` and `P2` here may be custom patterns, each of which destructs the data with
one perspective, and extract something we'd use latter.

This can be very frequent in the real world, say we're working with URL strings,
assume that we've implemented some small patterns like `Urlsplit` and `Urlopen`,
which respectively uses `urllib.parse.urlsplit` and `urllib.request.urlopen`
and presents destructed results:

```python
match url:
    case Urlsplit(netloc=n) and Urlopen(code=c)
        if c == 404 and n == "docs.python.org":
        ...
```

Without AND patterns, we cannot reuse the existing patterns like
`Urlsplit` or `Urlopen`. This disables the composability/modularity of programs.

By providing AND patterns, it becomes feasible for us to decouple our codes by implementing small patterns.
The users can reuse our patterns by combining them with AND patterns and OR patterns, even if we don't know how our code will get used.

## Grammar

### Parameterized Patterns

The parameterized patterns can be very convenient in practice, and See [F# Official Documents: Parameterized Active Patterns](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/active-patterns#parameterized-active-patterns).

This can be naturally achieved in Python, by changing the [grammar](https://github.com/brandtbucher/cpython/blob/276c2b08270861f939f79b6ceec995effe83073f/Grammar/python.gram#L253) from

```
class_pattern[expr_ty]:
    | func=name_or_attr '(' ')' { _Py_Call(func, NULL, NULL, EXTRA) }
```

to

```
class_pattern[expr_ty]:
    | func=call_or_attr '(' ')' { _Py_Call(func, NULL, NULL, EXTRA) }
    | ...

call_or_attr[expr_ty]:
    | call  # derives python's call syntax
    | NAME

call: ... # maybe 'primary'
```

In my implementation of pattern matching, [moshmosh](https://github.com/thautwarm/moshmosh), a pattern is just an `expr`, For instance:

```python
from moshmosh.extension import perform_extension
from inspect import getsource
import re

def rewrite(f):
    src = getsource(f)
    src = perform_extension(src)
    exec(src, f.__globals__)
    return f.__globals__[f.__name__]

class Regex:
    def __init__(self, r):
        self.p = re.compile(r)

    # this is different from PEP 622 proposal,
    # and also slightly differs from
    # the proposal by this article
    def __match__(self, n_arg, instance):
        if n_arg == 1:
            match = self.p.match(instance)
            return match and match.groups()

def test():
# +pattern-matching
    with match("PEP 622!"):
        if Regex("PEP (\d+\!)")(a):
            print(a)
        if _:
            print("not matched")

rewrite(test)()
#=> 622!
```

Also, this will make `InRange(lo, hi)` more efficiently:

```python
class InRange:
    def __init__(self, lo, hi):
        self.range = range(lo, hi)

    def __match__(self, instance):
        if instance in self.range:
            return self
match 5:
    case InRange(0, 10)():
        ...
```